/**
 * LLMæœåŠ¡ - åŸºäºåŸé¡¹ç›®çš„LLMæä¾›è€…åŒ…è£…
 */
import { apiClient } from './apiClient';

class LLMServiceError extends Error {
  constructor(message, type = 'UNKNOWN', originalError = null) {
    super(message);
    this.name = 'LLMServiceError';
    this.type = type;
    this.originalError = originalError;
  }
}

class LLMService {
  constructor() {
    this.model = process.env.REACT_APP_LLM_MODEL || 'gpt-4o';
    this.temperature = parseFloat(process.env.REACT_APP_LLM_TEMPERATURE) || 0;
    this.maxTokens = parseInt(process.env.REACT_APP_LLM_MAX_TOKENS) || 4000;
    this.isConnected = false;
  }

  /**
   * è·å–èŠå¤©å®Œæˆå“åº”
   * @param {Array} messages - æ¶ˆæ¯å†å²
   * @param {Object} options - å¯é€‰é…ç½®
   */
  async getChatCompletion(messages, options = {}) {
    const {
      model = this.model,
      temperature = this.temperature,
      maxTokens = this.maxTokens,
      stream = false
    } = options;

    try {
      const requestData = {
        messages: messages.map(msg => ({
          role: msg.role,
          content: msg.content
        })),
        model,
        temperature,
        max_tokens: maxTokens,
        stream
      };

      console.log('ğŸ¤– è°ƒç”¨LLMæœåŠ¡:', { model, temperature, messageCount: messages.length });

      const response = await apiClient.post('/functions/v1/llm-request', requestData);

      if (response.code === 200) {
        this.isConnected = true;
        return {
          content: response.data.content,
          usage: response.data.usage,
          model: response.data.model
        };
      } else {
        throw new LLMServiceError(
          response.message || 'LLM APIè¿”å›é”™è¯¯',
          'API_ERROR',
          response
        );
      }
    } catch (error) {
      this.isConnected = false;
      
      if (error instanceof LLMServiceError) {
        throw error;
      }

      if (error.type === 'NETWORK_ERROR') {
        throw new LLMServiceError(
          'æ— æ³•è¿æ¥åˆ°LLMæœåŠ¡ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒæœåŠ¡çŠ¶æ€',
          'CONNECTION_ERROR',
          error
        );
      }

      if (error.type === 'RESPONSE_ERROR') {
        throw new LLMServiceError(
          error.message || 'LLMæœåŠ¡å“åº”é”™è¯¯',
          'API_ERROR',
          error
        );
      }

      throw new LLMServiceError(
        error.message || 'LLMæœåŠ¡è°ƒç”¨å¤±è´¥',
        'UNKNOWN',
        error
      );
    }
  }

  /**
   * æµå¼å“åº”å¤„ç†
   */
  async getChatCompletionStream(messages, options = {}, onChunk) {
    const streamOptions = { ...options, stream: true };
    
    try {
      // æ³¨æ„: è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„æµå¼APIå®ç°
      // ç›®å‰å…ˆè¿”å›æ™®é€šå“åº”
      const result = await this.getChatCompletion(messages, streamOptions);
      if (onChunk) {
        onChunk(result.content);
      }
      return result;
    } catch (error) {
      throw error;
    }
  }

  /**
   * å¥åº·æ£€æŸ¥
   */
  async healthCheck() {
    try {
      const testMessages = [{
        role: 'user',
        content: 'Hello, are you working?'
      }];

      await this.getChatCompletion(testMessages, { 
        model: this.model, 
        temperature: 0,
        maxTokens: 50 
      });
      
      this.isConnected = true;
      return { status: 'healthy', connected: true };
    } catch (error) {
      this.isConnected = false;
      return { 
        status: 'unhealthy', 
        connected: false, 
        error: error.message 
      };
    }
  }

  /**
   * è·å–æœåŠ¡çŠ¶æ€
   */
  getStatus() {
    return {
      isConnected: this.isConnected,
      model: this.model,
      temperature: this.temperature,
      maxTokens: this.maxTokens
    };
  }

  /**
   * æ›´æ–°é…ç½®
   */
  updateConfig(config) {
    if (config.model) this.model = config.model;
    if (config.temperature !== undefined) this.temperature = config.temperature;
    if (config.maxTokens) this.maxTokens = config.maxTokens;
    
    if (config.apiToken) {
      apiClient.setAuthToken(config.apiToken);
    }
    if (config.baseURL) {
      apiClient.updateConfig({ baseURL: config.baseURL });
    }
  }

  /**
   * è§£æReActå“åº”æ ¼å¼
   */
  parseReActResponse(text) {
    const thoughtMatch = text.match(/Thought: (.*?)(?=\n|$)/);
    const actionMatch = text.match(/Action: (.*?)(?=\n|$)/);
    const argsMatch = text.match(/Args: ({.*?})(?=\n|$)/);

    if (thoughtMatch && actionMatch && argsMatch) {
      try {
        return {
          type: 'action',
          thought: thoughtMatch[1].trim(),
          action: actionMatch[1].trim(),
          args: JSON.parse(argsMatch[1].trim()),
          raw: text
        };
      } catch (error) {
        return {
          type: 'parse_error',
          error: 'Failed to parse JSON args',
          raw: text
        };
      }
    }

    return {
      type: 'final_answer',
      content: text,
      raw: text
    };
  }
}

// å…¨å±€å®ä¾‹
export const llmService = new LLMService();
export { LLMServiceError };
export default LLMService;